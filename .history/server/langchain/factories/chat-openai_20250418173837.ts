import type { ChatOpenAIData } from '@/types/node-data/chat-openai'
import type { BuildContext, FlowNode, InputPortVariable } from '~/types/workflow'
import { RunnableLambda } from '@langchain/core/runnables'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { ChatOpenAI } from '@langchain/openai'

import { resolveInputVariables } from '../../langchain/resolveInput'

export async function chatOpenAIFactory(node: FlowNode, context: BuildContext) {
  const data = node.data as ChatOpenAIData
  const {
    modelName,
    temperature,
    streaming,
    inputTextVariable,
    systemMessageVariable,
    apiKeyVariable,
    baseURLVariable,
    messageOutputVariable,
    languageModelOutputVariable,
  } = data
  
  const variableDefs = [inputTextVariable, systemMessageVariable, apiKeyVariable, baseURLVariable] as InputPortVariable[]
 

  const inputValues = await resolveInputVariables(context, variableDefs)
  

  const model = new ChatOpenAI({
    modelName,
    temperature,
    streaming,
    openAIApiKey: inputValues[apiKeyVariable.name],
    configuration: { baseURL: inputValues[baseURLVariable.name] },
  })

  const prompt = await ChatPromptTemplate.fromMessages([
    ['system', '{system}'],
    ['human', '{input}'],
  ]).partial({
    input: inputValues[inputTextVariable.name],
    system: inputValues[systemMessageVariable.name],
  })

  // return prompt.pipe(model)
  // ç»„åˆæˆ chain(å¯æ‰§è¡Œrunnable)

  const chain = prompt.pipe(model)
  // const finalPrompt = await prompt.invoke({})

  // // æ‰“å°ç»“æž„åŒ–ç»“æžœ
  // console.log('ðŸ“ prompt.invoke ç»“æžœ:', await chain.invoke({}))
  // å¦‚æžœ outputVariable æ²¡æœ‰ idï¼Œå°±ç»™ä¸ªé»˜è®¤
  const messagePortId = messageOutputVariable.id
  const lmPortId = languageModelOutputVariable.id
  // ðŸ‘‡ åŒæ—¶è¿”å›žä¸¤ä¸ªç«¯å£
  return {
    // ç«¯å£1: æä¾›å¯æ‰§è¡Œ chain(æœ€ç»ˆä¼šè¿”å›ž Message)
    [messagePortId]: chain,

    // ç«¯å£2: æä¾› model æœ¬èº«(å¯èƒ½ä½œä¸ºä¸‹æ¸¸ if needed)
    [lmPortId]: RunnableLambda.from(async () => {
                return model
            })
  }
}
