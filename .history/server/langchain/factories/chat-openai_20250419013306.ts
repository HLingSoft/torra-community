import type { ChatOpenAIData } from '@/types/node-data/chat-openai'
import type { BuildContext, FlowNode, InputPortVariable } from '~/types/workflow'
import { RunnableLambda } from '@langchain/core/runnables'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { ChatOpenAI } from '@langchain/openai'
import { AIMessage } from '@langchain/core/messages'
import { resolveInputVariables,normalizeToString } from '../../langchain/resolveInput'
// function normalizeToString(value: any): string {
//   if (value?.content && typeof value.content === 'string') return value.content
//   if (typeof value === 'string') return value
//   return JSON.stringify(value)
// }

export async function chatOpenAIFactory(node: FlowNode, context: BuildContext) {
  const data = node.data as ChatOpenAIData
  const {
    modelName,
    temperature,
    streaming,
    inputTextVariable,
    systemMessageVariable,
    apiKeyVariable,
    baseURLVariable,
    messageOutputVariable,
    languageModelOutputVariable,
  } = data
  
  const variableDefs = [inputTextVariable, systemMessageVariable, apiKeyVariable, baseURLVariable] as InputPortVariable[]
 

  const inputValues = await resolveInputVariables(context, variableDefs)
  

  const model = new ChatOpenAI({
    modelName,
    temperature,
    streaming,
    openAIApiKey: inputValues[apiKeyVariable.name],
    configuration: { baseURL: inputValues[baseURLVariable.name] },
  })

  const prompt = await ChatPromptTemplate.fromMessages([
    ['system', '{system}'],
    ['human', '{input}'],
  ]).partial({
    input:normalizeToString(inputValues[inputTextVariable.name])  ,
    system: normalizeToString(inputValues[systemMessageVariable.name]),
  })
  // console.log('chat-openai inputValues[inputTextVariable.name]:', inputValues[inputTextVariable.name])

  // return prompt.pipe(model)
  // ç»„åˆæˆ chain(å¯æ‰§è¡Œrunnable)

  const chain = prompt.pipe(model)

  // const finalMessages = await prompt.formatMessages({})
  // console.log('chat-openai final prompt:', finalMessages)

  // // æ‰“å°ç»“æ„åŒ–ç»“æœ
  // console.log('ğŸ“ prompt.invoke ç»“æœ:', await chain.invoke({}))
  // å¦‚æœ outputVariable æ²¡æœ‰ idï¼Œå°±ç»™ä¸ªé»˜è®¤
  const messagePortId = messageOutputVariable.id
  const lmPortId = languageModelOutputVariable.id
  // console.log('lmPortId', model.invoke())
  // ğŸ‘‡ åŒæ—¶è¿”å›ä¸¤ä¸ªç«¯å£
  return {
    // ç«¯å£1: æä¾›å¯æ‰§è¡Œ chain(æœ€ç»ˆä¼šè¿”å› Message)
    [messagePortId]:   new AIMessage(await chain.invoke({})),

    // ç«¯å£2: æä¾› model æœ¬èº«(å¯èƒ½ä½œä¸ºä¸‹æ¸¸ if needed)
    [lmPortId]: model
  }
}
